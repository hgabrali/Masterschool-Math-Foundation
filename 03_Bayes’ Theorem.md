# Bayes’ Theorem / Bayes Teoremi
---
# Bayes Teoremi'ne Katkıda Bulunan Bilim İnsanları (Tarihsel Kronoloji)

Bayes Teoremi, tek bir keşiften ziyade, zaman içinde geliştirilmiş bir fikirdir. İşte bu sürecin anahtar isimleri ve katkıları:

---

## 1. Thomas Bayes (1702–1761)

| Rolü | Katkısı |
| :--- | :--- |
| **Teoremin Fikir Babası** | Teoremin temel fikrini ortaya koyan İngiliz istatistikçi ve din adamıdır. |
| **Eseri** | Ölümünden sonra 1763'te yayımlanan *An Essay towards solving a Problem in the Doctrine of Chances* makalesidir. |
| **Temel Fikir** | Olasılığı bilinen olaylar için **ters olasılığı** (yani, **nedenden sonuca gitmeyi**) hesaplamanın genel bir yolunu geliştirmiştir. |

---

## 2. Pierre-Simon Laplace (1749–1827)

| Rolü | Katkısı |
| :--- | :--- |
| **Teoremi Formüle Eden ve Yaygınlaştıran** | Teoremi **modern formuna** sokan ve uygulamalarını genişleten Fransız matematikçi ve gökbilimcidir. |
| **Temel Fikir** | Teoremi 1774 yılında bağımsız olarak yeniden keşfetti, ispatladı ve günümüzde kullanılan daha genel matematiksel ifadeyi kesinleştirdi. Teoremi astronomiden tıbba kadar geniş bir alanda uygulamıştır. |

---

## 3. Sir Harold Jeffreys (1891–1989)

| Rolü | Katkısı |
| :--- | :--- |
| **Bayesci İstatistiğin Yeniden Canlanması** | 20. yüzyılın başlarında, klasik istatistiğin hakimiyetinde iken **Bayesci yöntemin gücünü** yeniden vurguladı. |
| **Eseri** | 1939 tarihli *Theory of Probability* (Olasılık Teorisi) adlı kitabıyla modern **Bayesci Analizin** temellerini attı. |

---

## Kronolojik Özet

| Yıl | Gelişme | Katkıda Bulunan |
| :--- | :--- | :--- |
| **1763** | Teoremin temel fikri ölümünden sonra yayımlandı. | **Thomas Bayes** |
| **1774** | Teorem modern haliyle bağımsız olarak yeniden keşfedilip formüle edildi. | **Pierre-Simon Laplace** |
| **1939** | Modern Bayesci istatistik yöntemleri için teorik temeller atıldı. | **Sir Harold Jeffreys** |


[Bayes Teoremi - Vikipedi (Teknik Detaylar)](https://en.wikipedia.org/wiki/Bayes%27_theorem)


# Bayes Teoremi Neden Kritik Öneme Sahiptir?

**Bayes Teoremi'nin** temel önemi, bize inançlarımızı **rasyonel bir şekilde güncelleme** imkanı vermesinden kaynaklanır. Yeni veriler (kanıtlar) ortaya çıktıkça, teorem, ilk hipotezimize olan güvenimizi nasıl değiştirmemiz gerektiğini matematiksel olarak kesin bir dille belirtir.

İşte Bayes Teoremi'ni istatistik ve modern teknoloji için vazgeçilmez kılan dört ana neden:

---

## 1. Belirsizlik Altında Karar Vermenin Temeli

Bayes Teoremi, **belirsizlikle başa çıkmak** için sağlam bir matematiksel çerçeve sunar. Gerçek dünyada, olayların olasılıkları nadiren kesindir. Teorem, bir hipoteze dair başlangıçtaki inancımızı (**öncül olasılık**), yeni gözlemler (test sonuçları, sensör verileri) ışığında değiştirmeyi modeller.

* **Güncelleme Mekanizması:** Teorem, "Bu olaya başlangıçta ne kadar inanırdım?" sorusundan, **"Bu yeni kanıtı gördükten sonra ne kadar inanmalıyım?"** sorusuna geçişin kesin formülüdür.

## 2. İstatistiksel Çıkarımın Doğal Modeli

Bayesci istatistik yaklaşımı, klasik (Frequentist) istatistiğin aksine, **öncül bilgiyi** (deney öncesi bilgiyi) modellemeye resmi olarak dahil etmemizi sağlar.

* **Öncül Bilginin Kullanımı:** Eğer bir olayın çok nadir olduğunu biliyorsak, Bayes Teoremi bu bilgiyi (**öncül olasılığı**) kullanır. Örneğin, çok nadir bir hastalık için pozitif test sonucu aldığınızda, teorem testin doğruluğu ile hastalığın nadirliğini dengeleyerek **daha gerçekçi bir olasılık** sunar ve aşırı çıkarımlardan kaçınır.

## 3. Makine Öğrenimi ve Yapay Zekanın Kalbi

Bayes Teoremi, günümüz teknolojilerinden birçoğunun temelini oluşturur ve Yapay Zeka (AI) alanında kritik uygulamalara sahiptir:

* **Naive Bayes Sınıflandırıcılar:** Metin sınıflandırma (örneğin, **e-posta filtreleme**), spam tespiti ve duygu analizi gibi alanlarda kullanılan, hem basit hem de oldukça etkili algoritmalardan biridir.
* **Bayes Ağları:** Karmaşık sistemlerdeki değişkenler arasındaki koşullu bağımlılıkları modellemek için kullanılır. Özellikle **uzman sistemlerde** ve **otonom araçlarda** karar verme süreçlerini destekler.

## 4. Bilimsel Yöntemin Matematiksel İfadesi

Bilimsel yöntem, hipotez kurma, veri toplama ve hipotezi kanıtlar ışığında revize etme üzerine kuruludur. Bayes Teoremi, bu **rasyonel revizyon sürecinin** matematiksel karşılığıdır. Bir bilim insanı, topladığı verilere göre bir hipoteze ne kadar inanması gerektiğini, teorem sayesinde objektif olarak belirleyebilir.


# Özet: Bayes Teoremi'nin Alanlara Göre Rolü

Bayes Teoremi'nin farklı akademik ve teknolojik alanlardaki temel işlevleri aşağıda özetlenmiştir.

| Alan | Bayes Teoremi'nin Rolü |
| :--- | :--- |
| **İstatistik/Olasılık** | Yeni kanıtlar ışığında başlangıç inançlarını (**öncül olasılık**) rasyonel ve matematiksel olarak kesin bir şekilde **günceller**. |
| **Karar Teorisi** | Belirsizlik altında en doğru kararı verme olasılığını hesaplar. |
| **Yapay Zeka (AI)** | Sınıflandırma, tahmin ve çıkarım algoritmalarının (özellikle **Naive Bayes**) temelini oluşturur. |
| **Bilimsel Çıkarım** | Hipotezlerin, toplanan verilerle ne kadar desteklendiğini objektif olarak ölçer. |


---

## Sonuç

**Bayes Teoremi**, sadece akademik bir formül değil; belirsizlikle dolu dünyamızda **rasyonel çıkarım yapma** ve **bilgiyi etkin bir şekilde kullanma** sanatının matematiksel anahtarıdır.


---

# Makine Öğrenimi ve Büyük Veri'de (Big Data) Bayes Teoremi'nin Önemi

Bayes Teoremi, günümüz teknolojisinin iki ana direği olan **Makine Öğrenimi (Machine Learning)** ve **Büyük Veri (Big Data)** alanlarında belirsizliği yönetmek, bilgiyi güncellemek ve en iyi tahminleri yapmak için vazgeçilmez bir matematiksel çerçeve sunar.

---

## Makine Öğrenimi'nde (ML) Merkezi Rolü

Makine öğrenimi, veriye dayalı tahminler ve çıkarımlar yapmayı amaçlar. Bayes Teoremi, bu sürecin temelini oluşturan **inanç güncelleme** mekanizmasını sağlar.

### 1. Sınıflandırmanın Temeli: Naive Bayes Algoritması

Bayes Teoremi, basit ama son derece etkili bir denetimli öğrenme algoritması olan **Naive Bayes (Saf Bayes) Sınıflandırıcısı'nın** temelini oluşturur.

* **Çalışma Prensibi:** Verilen bir veri noktasının (örneğin bir e-posta metninin) belirli bir sınıfa (örneğin "spam") ait olma olasılığını Bayes Teoremi kullanarak hesaplar.
* **Uygulama Alanları:**
    * **Metin Sınıflandırma:** E-posta spam filtreleme ve haber makalesi kategorizasyonu.
    * **Duygu Analizi:** Metinlerin pozitif, negatif veya nötr olduğunu tahmin etme.

### 2. İnanç Güncelleme ve Ön Bilginin Kullanımı

Bayesci yaklaşım, öğrenme sürecini doğrudan modeller.

* **Öncül Bilgi:** Modele, eğitime başlamadan önce sahip olduğumuz bilgileri (**öncül olasılık**) dahil etmemizi sağlar.
* **Güncelleme:** Yeni veri (kanıt) geldikçe, modelin parametrelerine olan inançlarımız (**arka olasılık**) sürekli ve matematiksel olarak kesin bir şekilde güncellenir.

### 3. Bayesci Çıkarım ve Belirsizliğin Ölçülmesi

Geleneksel ML modellerinin aksine, Bayesci yöntemler tahminlerini bir **olasılık dağılımı** olarak sunar.

* **Güven Aralığı:** Bu yaklaşım, sadece bir tahmin değeri vermek yerine, tahminin ne kadar güvenilir olduğunu da (**belirsizlik ölçüsü**) belirtir. Bu, tıbbi teşhis veya otonom sürüş gibi kritik sistemlerde hayati önem taşır.

---

## Büyük Veri'de (Big Data) Önemi

Büyük Veri setlerinden anlamlı ve eyleme geçirilebilir içgörüler çıkarma süreci, Bayes Teoremi sayesinde daha verimli ve güvenilir hale gelir.

### 1. Ölçeklenebilirlik ve Çevrimiçi Öğrenme

Büyük Veri, sürekli akış halinde gelir ve tüm veri setini aynı anda işlemek zordur.

* **Ardışık Öğrenme (Sequential Learning):** Bayesci yaklaşımlar, Teoremin ardışık güncelleme mantığı sayesinde, verileri parça parça veya akış halinde işleyerek modelleri sürekli güncelleyebilir. Bu, **çevrimiçi öğrenme (Online Learning)** için idealdir.

### 2. Veri Füzyonu ve Güvenilirleştirme

Büyük Veri, genellikle farklı kaynaklardan gelen gürültülü ve eksik bilgiyi içerir.

* **Bilgi Birleştirme:** Bayes Teoremi, farklı sensörlerden veya veri kaynaklarından gelen bilgileri ağırlıklandırarak birleştirmek için mükemmel bir araçtır. Bu **veri füzyonu** (data fusion) yeteneği, kararların farklı kaynaklardan gelen verilere dayalı olarak güvenilir bir şekilde alınmasını sağlar.

### 3. Gerçek Zamanlı Tahminler

* **Hızlı Kararlar:** Finans ve e-ticaret gibi alanlarda, bir kullanıcının geçmiş verilerini (**öncül olasılık**) ve mevcut bağlamını birleştirerek, reklam tıklama olasılığı gibi gerçek zamanlı tahminlerin saniyeler içinde yapılabilmesine olanak tanır.

---

## Özet Tablo: Bayes Teoremi'nin Rolü

| Alan | Neden Kritik? | Anahtar Uygulama Örneği |
| :--- | :--- | :--- |
| **Makine Öğrenimi** | Belirsizlik altında rasyonel tahmin ve parametre güncellemesi sağlar. | **Naive Bayes Sınıflandırıcıları** (Spam Tespiti) |
| **Büyük Veri** | Ardışık gelen veri akışlarını işler, farklı kaynakları birleştirir ve tahmin güvenilirliğini ölçer. | **Gerçek Zamanlı Reklam/Öneri Sistemleri** |

---

Bayes Teoremi, özetle, belirsizlikle dolu dünyamızda **rasyonel çıkarım yapma** ve **bilgiyi etkin bir şekilde kullanma** becerimizin matematiksel anahtarıdır.



---
# Bayes Teoremi (Bayes' Theorem)

## Giriş ve Tanım

**Bayes Teoremi**, bir olayın olasılığını, o olayla ilişkili olabilecek **önceden bilinen koşullara** (veya **öncül bilgilere**) dayanarak yeniden hesaplamamızı sağlayan matematiksel bir formüldür.

Özünde, bu teorem **yeni kanıtlar (data)** ışığında bir hipotezin (olayın) **inandırıcılığını (olasılığını) güncellememizi** sağlar. Teoremin formülü, koşullu olasılık formülünden türetilmiştir.

---

## Bayes Teoremi Formülü

Olay $A$ (Hipotez) ve Olay $B$ (Kanıt) için Bayes Teoremi şu şekilde ifade edilir:

$$\mathbf{P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}}$$

---

## Formül Bileşenlerinin Teknik Açıklaması

Bayes Teoremi'nin her bir bileşenini ve analitik rolünü detaylıca inceleyelim:

### 1. Arka Olasılık (Posterior Probability)

$$\mathbf{P(A|B)}$$

* **Tanım:** $B$ olayı **gerçekleştiği bilindiğinde**, $A$ olayının gerçekleşme olasılığıdır.
* **Amaç:** Ulaşmak istediğimiz nihai olasılıktır. Yeni kanıt ($B$) geldikten sonra $A$ hipotezinin ne kadar doğru olduğunu gösterir.

### 2. Olabilirlik (Likelihood)

$$\mathbf{P(B|A)}$$

* **Tanım:** $A$ hipotezinin **doğru olduğu varsayıldığında**, $B$ kanıtının (verisinin) gözlemlenme olasılığıdır.
* **Rolü:** Hipotezimizin, gözlemlediğimiz veriyi ne kadar iyi açıkladığını ölçer. Bu terim, hipotezin kanıtla ne kadar uyumlu olduğunu gösterir.

### 3. Öncül Olasılık (Prior Probability)

$$\mathbf{P(A)}$$

* **Tanım:** Herhangi bir yeni kanıt ($B$) görmeden **önce**, $A$ hipotezinin başlangıçtaki (marjinal) olasılığıdır.
* **Rolü:** Deney öncesi sahip olduğumuz bilgi düzeyini ve ilk inancımızı yansıtır.

### 4. Kanıt Olasılığı (Evidence or Marginal Probability)

$$\mathbf{P(B)}$$

* **Tanım:** $A$ hipotezinden bağımsız olarak, $B$ kanıtının (verisinin) **genel olarak** gerçekleşme olasılığıdır.
* **Rolü:** Paydadaki bu terim, tüm olası senaryolar (hem $A$ doğru iken hem de $A$ yanlış iken) altında $B$ kanıtının gerçekleşme olasılığını hesaplayarak, Arka Olasılığı doğru bir şekilde **normalleştirmeye** yarar.

#### $P(B)$'nin Açılımı (Toplam Olasılık Kuralı - Total Probability Rule)

Genellikle $P(B)$ doğrudan bilinmez, bu yüzden $A$ ve $A^c$ ($A$'nın tümleyeni, yani $A$'nın gerçekleşmemesi) olayları üzerinden hesaplanır.

---

# Bayes’ Theorem 

# Introduction to Bayes' Theorem

Bayes' Theorem is a powerful tool in probability theory that allows us to **update probabilities** based on new information.

It provides a way to calculate the probability of an event given that another event has occurred, effectively incorporating **prior knowledge** or evidence into our calculations. The theorem serves as the foundation for **Bayesian inference**, which is crucial in fields ranging from statistics and machine learning to scientific hypothesis testing.

<img width="714" height="581" alt="image" src="https://github.com/user-attachments/assets/6e87b552-a22e-4dd2-a9b6-580908a60a74" />

<img width="671" height="167" alt="image" src="https://github.com/user-attachments/assets/7151b981-3a7b-4dac-8fcf-cda734844dcd" />

# Marginal Probability

**Marginal probability** refers to the likelihood of an event occurring, **irrespective of the outcomes of other related events**. It represents the probability of a single event taking place, considered in isolation from a full set of joint probabilities.

If events $A_1, A_2, \dots, A_n$ form a **mutually exclusive and exhaustive set** (meaning one of them must occur and they cannot occur simultaneously), and event $B$ can happen under the condition of any $A_i$, then the probability of event $B$ is given by the **Law of Total Probability**:

$$\mathbf{P(B) = \sum_{i=1}^{n} P(B|A_i) \cdot P(A_i)}$$

This formula calculates the marginal probability of $B$ by summing the joint probabilities of $B$ occurring with each possible event $A_i$.

---

## Example: Boxes with Marbles

Let's look at an example to understand how to calculate the marginal probability of drawing a specific color.

**Scenario:**
Suppose we have two boxes: a **Yellow box ($A_Y$)** and a **Green box ($A_G$)**. Each box contains marbles (balls), either red or blue.

| Box | Blue Marbles | Red Marbles | Total |
| :--- | :--- | :--- | :--- |
| **Yellow ($A_Y$)** | 1 | 1 | 2 |
| **Green ($A_G$)** | 6 | 2 | 8 |

**Question:**
If we were to draw a red marble blindly, which box would it be most likely to come from?

To answer this, we need to find the conditional probabilities $P(A_Y|R)$ and $P(A_G|R)$ using Bayes' Theorem, which requires the marginal probability of drawing a Red marble, $P(R)$.

Let $P(A_Y) = 1/2$ and $P(A_G) = 1/2$ (assuming we choose a box randomly).

The **Marginal Probability of drawing a Red marble ($P(R)$)** is calculated as:
$$P(R) = P(R|A_Y) \cdot P(A_Y) + P(R|A_G) \cdot P(A_G)$$

1.  **Probability of Red from Yellow Box:** $P(R|A_Y) = 1/2$
2.  **Probability of Red from Green Box:** $P(R|A_G) = 2/8 = 1/4$

$$P(R) = \left(\frac{1}{2} \cdot \frac{1}{2}\right) + \left(\frac{1}{4} \cdot \frac{1}{2}\right) = \frac{1}{4} + \frac{1}{8} = \frac{2}{8} + \frac{1}{8} = \frac{3}{8}$$

The marginal probability of drawing a red marble is $\mathbf{3/8}$.

<img width="753" height="500" alt="image" src="https://github.com/user-attachments/assets/27cd1990-520f-4617-9818-c3971eaed523" />

<img width="723" height="351" alt="image" src="https://github.com/user-attachments/assets/9895353d-c7f9-4e6d-a860-7bd3f8e22b38" />

<img width="764" height="680" alt="image" src="https://github.com/user-attachments/assets/9cc88d1b-f401-4a36-9bdf-517826102c96" />

# Key Insights from Bayes' Theorem

Bayes' Theorem provides a powerful, rational framework for updating beliefs. Here are the core insights derived from its application:

| Insight | Description |
| :--- | :--- |
| **Incorporating Prior Knowledge** | The theorem formally combines **prior probabilities** ($P(A)$) with **new evidence (likelihood)** ($P(B|A)$) to calculate a refined **posterior probability** ($P(A|B)$). This means initial knowledge is never discarded. |
| **Impact of Base Rates** | The **prior probability** (often called the **base rate**) significantly affects the posterior probability. Even if new evidence is strong (high likelihood), a very low initial base rate can still result in a low final probability. |
| **Real-World Applications** | It is widely used across various fields, including **medical testing** (diagnosing rare diseases), **spam detection** (Naive Bayes), **risk assessment**, and **A/B testing**. |

---

These insights highlight why Bayesian inference is a critical tool for navigating uncertainty and making data-driven decisions.

<img width="827" height="586" alt="image" src="https://github.com/user-attachments/assets/b91490b1-f3f5-44d5-9c36-884812d76ed9" />

<img width="739" height="711" alt="image" src="https://github.com/user-attachments/assets/6521fe6e-6d4f-4fb2-9c0c-f08e34751fe8" />

<img width="787" height="421" alt="image" src="https://github.com/user-attachments/assets/98f1f8e9-faa7-45c8-8677-d7c8addc4d19" />


---

# Uygulama Örneği: Bayes Teoremi ile Arızalı Makine Teşhisi

Bu örnek, Bayes Teoremi'nin yeni bir kanıt (kusurlu ürün) ışığında bir olayın nedenini (hangi makine) bulmak için nasıl kullanıldığını gösterir.

## Senaryo Detayları

Bir fabrika, toplam 10.000 ürün üreten üç makine (A, B, C) işletmektedir. Makinelere ait üretim oranları (**Öncül Olasılıklar**) ve kusur oranları (**Olabilirlikler**) aşağıdaki gibidir:

| Makine | Günlük Üretim | Ürünün O Makineden Gelme Olasılığı ($P(M)$) | Kusur Oranı ($P(\text{Kusurlu}|M)$) |
| :--- | :--- | :--- | :--- |
| **A** | 4.000 | $P(A) = 4000/10000 = \mathbf{0.40}$ | $P(D|A) = \mathbf{0.01}$ |
| **B** | 3.000 | $P(B) = 3000/10000 = \mathbf{0.30}$ | $P(D|B) = \mathbf{0.02}$ |
| **C** | 3.000 | $P(C) = 3000/10000 = \mathbf{0.30}$ | $P(D|C) = \mathbf{0.03}$ |

**Soru:** Rastgele seçilen bir ürünün **kusurlu (D)** olduğu biliniyorsa, bu ürünün her bir makineden gelme olasılığı ($P(A|D)$, $P(B|D)$, $P(C|D)$) nedir?

---

## Adım 1: Toplam Kusur Olasılığını Hesaplama (Marjinal Olasılık)

İlk olarak, fabrikada üretilen herhangi bir ürünün kusurlu olma genel olasılığını ($P(D)$), yani **Kanıt Olasılığını** hesaplamalıyız. Bu, her makineden kusurlu ürün gelme olasılığının toplamıdır (Toplam Olasılık Kuralı).

### Formül:
$$\mathbf{P(D) = P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)}$$

### Hesaplama:
$$\begin{aligned} P(D) &= (0.01 \cdot 0.40) + (0.02 \cdot 0.30) + (0.03 \cdot 0.30) \\ P(D) &= 0.004 + 0.006 + 0.009 \\ P(D) &= \mathbf{0.019} \end{aligned}$$

**Sonuç:** Fabrikada üretilen herhangi bir ürünün kusurlu olma genel olasılığı $\mathbf{0.019}$'dur (veya %1.9).

---

## Adım 2: Bayes Teoremi Uygulaması (Arka Olasılık)

Ürünün kusurlu olduğu **bilgisine** dayanarak, ürünün her bir makineden gelme olasılığını hesaplıyoruz. Bayes Teoremi'nin genel formülü şöyledir:

$$\mathbf{P(M|D) = \frac{P(D|M) \cdot P(M)}{P(D)}}$$

### A. Makine A'dan Gelme Olasılığı ($P(A|D)$)

$$\mathbf{P(A|D) = \frac{P(D|A) \cdot P(A)}{P(D)} = \frac{0.01 \cdot 0.40}{0.019} \approx \mathbf{0.2105}}$$

### B. Makine B'den Gelme Olasılığı ($P(B|D)$)

$$\mathbf{P(B|D) = \frac{P(D|B) \cdot P(B)}{P(D)} = \frac{0.02 \cdot 0.30}{0.019} \approx \mathbf{0.3158}}$$

### C. Makine C'den Gelme Olasılığı ($P(C|D)$)

$$\mathbf{P(C|D) = \frac{P(D|C) \cdot P(C)}{P(D)} = \frac{0.03 \cdot 0.30}{0.019} \approx \mathbf{0.4737}}$$

---

## Çözüm Özeti ve Çıkarım

| Makine | Öncül Olasılık ($P(M)$) | Arka Olasılık ($P(M|D)$) |
| :--- | :--- | :--- |
| **A** | $0.40$ (40%) | $\approx 0.2105$ (21.05%) |
| **B** | $0.30$ (30%) | $\approx 0.3158$ (31.58%) |
| **C** | $0.30$ (30%) | $\approx 0.4737$ (47.37%) |
| **TOPLAM** | $1.00$ | $1.00$ |

**Sonuç:** Kusurlu ürünün en yüksek olasılıkla **Makine C'den (%47.37)** geldiği sonucuna varılır.

**Temel Çıkarım:** Makine A en çok üretim yapmasına rağmen, Makine C'nin **yüksek kusur oranı** (Olabilirlik), ürünün kusurlu olduğu bilgisini aldığımızda, Makine C'den gelme olasılığını en yüksek seviyeye çıkarmıştır. Bayes Teoremi, öncül bilgiyi (üretim oranı) yeni kanıt (kusur) ile etkin bir şekilde birleştirmiştir.

---






